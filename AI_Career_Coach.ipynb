{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsamarnathoffl/AI_Career_Coach_GEN_AI/blob/main/AI_Career_Coach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5Z3JTpEhQa_"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install required packages\n",
        "!pip install langchain-google-genai langchain faiss-cpu PyPDF2 --quiet\n",
        "!pip install sentence-transformers --quiet\n",
        "!pip install -U langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azLMI-NahVaL"
      },
      "outputs": [],
      "source": [
        "# Step 2: Import modules\n",
        "import os\n",
        "import PyPDF2\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from google.colab import files\n",
        "import getpass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzLSqzPLrfwk"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExLV2untiGVM"
      },
      "outputs": [],
      "source": [
        "# Step 3: Setup Gemini API key\n",
        "# Safer way: prompt for key without exposing it\n",
        "GOOGLE_API_KEY = getpass.getpass(\"ðŸ”‘ Enter your Google Gemini API key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"models/gemini-2.0-flash\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsfrPVb8i2k0"
      },
      "outputs": [],
      "source": [
        "# Step 4: Setup text splitter and embeddings\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator='\\n',\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdLzWmcyi33E"
      },
      "outputs": [],
      "source": [
        "# Step 5: Upload your resume (PDF)\n",
        "uploaded = files.upload()\n",
        "pdf_path = next(iter(uploaded))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcKLRSBbjLsP"
      },
      "outputs": [],
      "source": [
        "# Step 6: Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text\n",
        "    return text\n",
        "\n",
        "resume_text = extract_text_from_pdf(pdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtP7FNGJjQC4"
      },
      "outputs": [],
      "source": [
        "# Step 7: Prompt template for summarizing resume\n",
        "resume_summary_template = \"\"\"\n",
        "Role: You are an AI Career Coach.\n",
        "\n",
        "Task: Given the candidate's resume, provide a comprehensive summary that includes the following key aspects:\n",
        "- Career Objective\n",
        "- Skills and Expertise\n",
        "- Professional Experience\n",
        "- Educational Background\n",
        "- Notable Achievements\n",
        "\n",
        "Instructions:\n",
        "Provide a concise summary of the resume, focusing on the candidate's skills, experience, and career trajectory. Ensure the summary is well-structured, clear, and highlights the candidate's strengths in alignment with industry standards.\n",
        "\n",
        "Requirements:\n",
        "{resume}\n",
        "\"\"\"\n",
        "\n",
        "resume_prompt = PromptTemplate(\n",
        "    input_variables=[\"resume\"],\n",
        "    template=resume_summary_template,\n",
        ")\n",
        "\n",
        "resume_analysis_chain = LLMChain(llm=llm, prompt=resume_prompt)\n",
        "resume_summary = resume_analysis_chain.run(resume=resume_text)\n",
        "\n",
        "formatted_summary = \"### Resume Summary\\n\\n\" + resume_summary\n",
        "display(Markdown(formatted_summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDf33WrwjR2G"
      },
      "outputs": [],
      "source": [
        "# Step 8: Build a QA System on Resume\n",
        "splitted_text = text_splitter.split_text(resume_text)\n",
        "vectorstore = FAISS.from_texts(splitted_text, embeddings)\n",
        "vectorstore.save_local(\"vector_index\")\n",
        "\n",
        "db = FAISS.load_local(\"vector_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
        "\n",
        "career_qa_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=\"\"\"\n",
        "You are an experienced AI Career Coach.\n",
        "\n",
        "You are helping a job seeker by answering questions based on their resume and your knowledge.\n",
        "\n",
        "Here is the relevant context from the candidate's resume:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Give a structured, actionable answer with advice and steps to improve the candidateâ€™s career prospects.\n",
        "\n",
        "If the resume context is insufficient, use your general career coaching expertise to provide helpful answers.\n",
        "\n",
        "Response should be straightforward and shorter without unnecessary information.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": career_qa_prompt_template}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq0ENQsQj2hE"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    query = input(\"Ask a question about your resume or career (or type 'exit' to quit): \")\n",
        "    if query.lower() == 'exit':\n",
        "        break\n",
        "    response = qa_chain.invoke(query)\n",
        "    display(Markdown(f\"**You:** {query}\"))\n",
        "    display(Markdown(f\"###AI Career Coach:\\n\\n{response['result']}\"))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOBkr7GcFx1DVQOCYCUt30",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}